# 現代ソフトウェア開発におけるハーネスエンジニアリングの包括的分析：Claude CodeとCodexを活用したAIエージェント駆動型プロダクト開発のベストプラクティス

## 序論：ソフトウェアエンジニアリングにおける自律型エージェントの台頭と新たなパラダイムの要請

近年のソフトウェア工学は、人工知能（AI）、とりわけ大規模言語モデル（LLM）の進化によって歴史的な変曲点を迎えている。2025年後半から2026年初頭にかけて、開発者の役割は単なる「コードの記述者」から、自律的に機能するAIエージェント群を指揮・管理する「オーケストレーター」へと劇的な移行を遂げた。GitHubリポジトリを対象とした大規模な調査では、AIコーディングツールが広く利用可能になってからわずか数ヶ月の間に、コードへの貢献の16%から23%がすでにこれらのツールを介して行われていると推定されている。著名なコンピュータ科学者であるAndrej Karpathy氏は、2025年11月時点では手動コーディングが80%を占めていた自身のワークフローが、わずか1ヶ月後の12月にはエージェント支援によるコーディングが80%を占める状態へと完全に逆転したと述べており、この変化の速度は熟練した実務家すらも驚嘆させるものであった。

しかし、AIモデルによるコード生成が日常化するにつれて、業界全体で深刻な課題が浮き彫りになり始めた。AIは極めて短時間で膨大なコードを生成できる一方で、ビジネスの文脈を欠落させたり、アーキテクチャの境界を無視した無秩序な実装を行ったりする傾向がある。その結果として、保守不能な技術的負債が急速に蓄積されるリスクが高まったのである。このような背景から、非決定的な出力を行うAIを決定論的なシステム開発の枠組みに安全に統合するための新たなエンジニアリング分野として「ハーネスエンジニアリング（Harness Engineering）」が提唱され、注目を集めている。

本報告書は、現代のプロダクト開発におけるハーネスエンジニアリングの理論的基盤を解き明かし、Anthropic社の「Claude Code」やOpenAI社の「Codex」といった最先端のエージェントを実際に運用する際のベストプラクティスを包括的に分析するものである。また、スモークテストや構造テストを通じた自動検証メカニズムの実装手法、仕様駆動型開発（SDD）の隆盛、そしてAIエージェントの導入が人間のソフトウェアエンジニアの認知能力やスキル形成に与える影響に至るまで、多角的な視点から次世代の開発手法の全容を詳述する。

## 開発アプローチの遷移：バイブコーディングの限界とハーネスエンジニアリングの必然性

AIを活用したコーディングの初期段階において業界を席巻したのが「バイブコーディング（Vibe Coding）」と呼ばれる手法である。この概念は2025年2月にAndrej Karpathy氏によって提唱されたものであり、開発者が自然言語を用いて直感的に要件を語りかけ、AIがそれを実行可能なコードへと変換する自由奔放なアプローチを指す。バイブコーディングは「まずコードを生成し、後から洗練させる」というアジャイルな思考と合致し、プロトタイピングやMVP（Minimum Viable Product）の構築、あるいは非エンジニアによる内部自動化スクリプトの作成において絶大な威力を発揮した。

しかし、エンタープライズ規模のソフトウェア開発において、バイブコーディングは重大な限界を露呈した。Addy Osmani氏の分析によれば、バイブコーディングは開発の初期の勢い（モメンタム）を生み出すには優れているものの、構造的な枠組みが欠如しているため、本番環境の厳しい要求の前ではシステムが容易に崩壊してしまう。同氏は、AIコーディングの時代における開発者のペルソナを三つに分類している。一つ目は、過剰なリスクを許容し、監視や制約を最小限にして野生の勘でシステムを構築する「ロデオカウボーイ（Rodeo Cowboys）」である。二つ目は、官僚主義や過度なプロセスに縛られて身動きが取れなくなっている「囚人（Prisoners）」である。そして三つ目が、プロンプトベースの迅速な開発を行いながらも、最終的な生成物のアーキテクチャ、セキュリティ、スケーラビリティに対して明確な説明責任を負う「プロフェッショナルなエンジニア」である。このプロフェッショナルなエンジニアリングをシステムとして実現するための方法論が、ハーネスエンジニアリングである。

Gergely Orosz氏やPeter Steinberger氏の実践が示すように、AIを真にスケールさせるためのインフラストラクチャは三つの階層に分類される。第一の階層は「プロンプトエンジニアリング」であり、AIへの指示の言語的な工夫に焦点を当てる。第二の階層は「コンテキストエンジニアリング」であり、適切なドキュメントや関連ファイルをAIのコンテキストウィンドウに提供することに注力する。そして第三の、最も高度な階層が「フィードバックループエンジニアリング」または「ハーネスエンジニアリング」である。ここでは、エージェントが自身の出力したコードを自動的にコンパイルし、テストを実行し、エラーをデバッグし、外部APIを本物のキーで叩いて動作確認を行う「閉じたループ（Closed-loop systems）」を構築することが主眼となる。

| 比較項目 | バイブコーディング (Vibe Coding) | ハーネスエンジニアリング (Harness Engineering) |
| :--- | :--- | :--- |
| 主たる目的と価値 | 開発の勢い、アイデアの迅速な具現化、初期構築速度の最大化 | 長期的な保守性の確保、アーキテクチャのコヒーレンス維持、品質の自動担保 |
| 開発プロセス | 直感的、会話型、コードファースト（生成後に洗練） | 構造的、制約ファースト、テストファースト（検証ループの事前構築） |
| 品質保証の手法 | 人間のエンジニアによる事後的な目視レビューと手動修正 | 決定論的なリンター、構造テスト、CIパイプラインによる機械的な強制 |
| 最適な適用領域 | 個人の自動化スクリプト、MVP、概念実証（POC）、小規模なプロトタイプ | 大規模商用プロダクト、長期運用システム、コンプライアンス要件の厳しい領域 |
| 人間の主要な役割 | アイデアの言語化、プロンプトの調整、AI生成物の受け入れ判断 | エージェントが活動する環境の設計、システム境界の定義、検証ツールの開発 |

テーブル 1: AI駆動型開発におけるバイブコーディングとハーネスエンジニアリングの比較分析

この移行は、ソフトウェア開発における「責任の所在」と「品質担保のメカニズム」を、人間個人の注意力から、システムとしての拘束力へとシフトさせる歴史的な転換点であると言える。

## ハーネスエンジニアリングの理論的基盤と中核概念

ハーネスエンジニアリングという用語が業界で確固たる地位を築く契機となったのは、著名なソフトウェアエンジニアであるMitchell Hashimoto氏の実践と、それに続くOpenAI社の大規模な実証実験である。Hashimoto氏の定義によれば、ハーネスエンジニアリングとは「AIエージェントが何らかのミスを犯したことを発見した際、エージェントが二度とその特定のミスを繰り返さないようにするための解決策を工学的に設計し、時間をかけて実装する実践」を指す。AIエージェントは、人間からの細かな修正指示を必要とせず、初回で正しい結果を出力できる場合に最も高い効率を発揮する。したがって、エージェントが「間違ったこと」をしたと認識した時点で、システム側で自動的にその過ちを検知・拒絶するツールやルールを提供することが、開発者の新たな責務となるのである。

この概念をエンタープライズレベルのプロダクト開発で極限まで追求したのがOpenAIの開発チームである。同チームは、社内のデイリーユーザーおよび外部のアルファテスター向けに提供されるソフトウェアプロダクトを開発するにあたり、「人間が手動でコードを1行も書かない」という極端な制約を課す実験を5ヶ月間にわたって実施した。アプリケーションのビジネスロジック、テストコード、CI（継続的インテグレーション）の設定ファイル、システムのドキュメント、監視・オブザーバビリティの設定、さらには内部ツールに至るまで、約100万行に及ぶコードベースと1,500件のプルリクエストが、すべてCodexエージェントによって生成・管理されたのである。

この壮大な実験が明らかにしたのは、開発が停滞する原因の根本的な見直しである。プロジェクトの初期段階において進捗が予想以上に遅れた際、その原因は「AIエージェントの推論能力が低いから」ではなく、「エージェントに与えられた環境の仕様定義が不十分であったから」であることが判明した。ビルドが失敗した際やテストが通らなかった際、プロンプトを通じてエージェントに「もっと頑張れ（try harder）」と指示することは根本的な解決にはならない。エンジニアが行うべき正しいアプローチは、エージェントが失敗したという事実をシグナルとして捉え、何が不足しているのか（ツール、ガードレール、あるいはドキュメント）を特定し、それをリポジトリ内の恒久的な仕組みとしてフィードバックすることであった。

Hashimoto氏のアプローチにおいても、このフィードバックループの構築には主に二つの形態が存在する。第一の形態は「より優れた暗黙的プロンプティング」であり、頻発する単純なエラー（例：エージェントが誤ったコマンドを実行し続ける、間違ったAPIエンドポイントを参照する等）に対して、リポジトリ内のAGENTS.mdのようなコンテキストファイルに明示的な禁止事項や正しい手順を追記することで、行動を是正する手法である。第二の形態は「プログラムされた実際のツール群」の提供である。これは、エージェントが自分自身の作業結果を視覚的に検証するためのスクリーンショット取得スクリプトや、特定の範囲のみを実行するフィルタリングテストツールなどを独自に開発し、エージェントにそのツールの存在と使用方法を教え込むことである。これにより、エージェントは自律的に「自分が良い仕事をしているか」を確認できるようになる。

### エージェントの可読性（Agent Legibility）とコンテキストアーキテクチャ

人間がコードを書かず、エージェントが主体となってシステムを構築・保守する環境においては、コードベースのファイル構成やドキュメントの構造に関するパラダイムも変化する。この新たなパラダイムの中核をなす概念が「エージェントの可読性（Agent Legibility）」である。従来のソフトウェア開発では、新しくチームに加わった人間のエンジニアがシステムを理解しやすいように、システムの全体像から詳細なモジュール設計までを網羅した巨大なマニュアルやWikiを整備することが一般的であった。しかし、完全なエージェント生成のコードベースにおいて、最適化の対象は人間の認知能力ではなく、AIモデルの推論能力とコンテキストウィンドウの効率性へと移る。

人間のエンジニアの目標は、エージェントがリポジトリを起点として、複雑なビジネスドメイン全体を直接的かつ正確に推論できるようにナビゲーションパスを設計することである。この目標を達成するために用いられる主要な手法が「段階的開示（Progressive Disclosure）」である。エージェントにシステムの情報を一括して与えるのではなく、エージェントが情報を探索するための「地図」を提供する。具体的には、リポジトリのルートに配置されるAGENTS.mdやCLAUDE.mdといったファイルは、システムのすべてを記述した百科事典として扱うのではなく、約100行程度の「目次（Table of contents）」として機能させる。これらのファイルは、技術スタックやプロジェクト構造の概要（WHAT）、プロジェクトの目的と各モジュールの存在理由（WHY）、そしてエージェントがどのように振る舞うべきかの指針（HOW）のみを簡潔に定義する。

そして、真実の情報源（System of record）となる詳細な知識ベースはdocs/ディレクトリ配下の構造化されたファイル群に格納され、ルートの目次ファイルからそれらへのポインタを提供する。これにより、エージェントは無関係な情報でコンテキストウィンドウを圧迫されることなく、当面のタスクに必要な詳細ドキュメントだけを自律的に読み込むことが可能となり、ハルシネーションの抑制と推論精度の向上が同時に達成される。エージェントの視点から見れば、「現在のコンテキスト内でアクセスできない情報は存在しないことと同義」であるため、オブザーバビリティデータやブラウザのナビゲーション履歴といった動的な状態も、エージェントが直接読み取れる形式（ログファイルやJSONストリーム等）でリポジトリ環境に露出させることが極めて重要となる。

## Claude Codeを用いた長期実行エージェントのベストプラクティス

現代のAIコーディングエージェントを代表するツールの一つであるAnthropic社の「Claude Code」は、開発者のターミナル内に常駐し、コードベースの深い理解に基づいて自然言語コマンドから複雑なタスクを自律的に実行する能力を備えている。シェルスクリプト、Python、TypeScriptなどを駆使して構成されたこのエージェントは、単なるコード補完ツールを超え、ディレクトリ内のファイル探索、コードの編集、コマンドの実行を並行して行うことができる。しかし、このような高度な自律性を持つエージェントを長期間にわたって安全に稼働させるためには、綿密に設計されたハーネスと状態管理のベストプラクティスが不可欠である。

Anthropic社が提唱する効果的なハーネスの要諦は、エージェントが直面しやすい四つの典型的な失敗モード（プロジェクト全体の完了を早急に宣言してしまう、バグや未文書化の進捗を残したまま環境を放棄する、個々の機能を十分にテストせずに完了とする、アプリケーションの実行方法を毎回ゼロから推論しようとして時間を浪費する）をシステム的に防ぐことにある。これらの課題を解決するため、複雑なマルチコンテキストウィンドウのワークフローにおいては、単一のセッションで要件定義から実装まですべてを行わせるのではなく、「イニシャライザエージェント（Initializer Agent）」と「コーディングエージェント（Coding Agent）」という二つの異なるペルソナ（プロンプト）を使い分けるアプローチが強く推奨されている。

最初のコンテキストウィンドウで起動されるイニシャライザエージェントには、直接的なコードの記述を求めるのではなく、将来のコーディングエージェントが効率的に作業するための土台作りを指示する。具体的には、入力された仕様書に基づいてエンドツーエンドの機能説明を網羅した構造化されたJSONファイル（機能リスト）を作成させる。また、開発サーバーの起動、テストスイートの実行、リンターの適用などを優雅に処理するための環境セットアップスクリプト（init.shなど）を記述させ、初期のGitリポジトリの初期化と進行状況ノート（Progress notes）の作成を行わせる。

環境が整備された後に起動するコーディングエージェントに対しては、毎回のセッションの開始時に必ずinit.shを実行し、進行状況ノートとGitのコミットログを読み込むようプロンプトで強制する。これにより、エージェントは過去のセッションでどこまで作業が進んだのか、どのようなバグが未解決のまま残されているのかという状態（State）を正確に復元することができる。作業の進行中、エージェントは自由形式のテキストファイルを用いて自己の文脈を記録し、並行してGitを用いて状態のチェックポイントを作成していく。最新のClaudeモデルは、複数のセッションにまたがってGitを用いて状態を追跡する能力に特に優れている。

さらに、長時間の自律的なタスク実行において最も重要なのが、エージェントが人間の継続的なフィードバックなしに自身の成果物の正当性を検証するメカニズムである。Claude Codeのベストプラクティスでは、タスクを開始する前にエージェントにテストコードを作成させ、それをtests.jsonのような構造化フォーマットで管理させることが推奨される。また、Playwright MCP（Model Context Protocol）サーバーのようなUIテストツールや、コンピューターユース（画面操作）機能を検証ツールとして提供することで、エージェントは自身が実装した機能を自己検証（Self-verify）し、慎重なテストを完全に通過した場合にのみ、JSON機能リスト上の当該機能を「合格（Passing）」としてマークすることが許される。

| エージェントの役割と状態 | 想定される主な課題（失敗モード） | ハーネスを通じた解決策とベストプラクティス |
| :--- | :--- | :--- |
| イニシャライザエージェント (最初のセッション) | エージェントがアプリの実行方法や依存関係の解決に時間を浪費する。 | 開発サーバーやテストを起動するための標準化されたinit.shスクリプトを生成させる。 |
| イニシャライザエージェント (最初のセッション) | タスクの規模を誤認し、プロジェクト全体を一度に完了したと誤って宣言する。 | 仕様に基づく詳細なエンドツーエンドの機能リストをJSON形式で事前に作成させる。 |
| コーディングエージェント (継続的なセッション) | 前回のセッションの状態を喪失し、未文書化のバグや不完全な状態を引き継ぐ。 | セッション開始時に必ずinit.sh、進行状況ノート、Gitログを読み込ませる。 |
| コーディングエージェント (継続的なセッション) | 実際には動かないコードを実装しただけで、機能を完了したと早急に判断する。 | Playwright等のMCPツールを用いた自己検証を強制し、テスト通過時のみ「完了」を許可する。 |
| タスクの高度な自律実行 | 複雑な問題解決において、インタラクティブな対話が邪魔になる場合がある。 | 「Deep Mode」を利用し、最長15分間、コードを静かに読み込み、深く推論してから実装を行わせる。 |

テーブル 2: Claude Codeにおける役割分離と状態管理のベストプラクティス

また、最新のツールエコシステムにおいては、高度な自律性を要求される問題解決のために「Deep Mode（ディープモード）」と呼ばれる特殊なエージェントモードも実用化されている。例えば、GPT-5.3-Codexを活用したAmpエディタのDeep Modeでは、エージェントは直ぐにコードを書き始めるのではなく、5分から15分にわたって沈黙のままコードベースを深く読み込み、複雑な依存関係を自律的に推論してから初めて変更に着手する。このような深い推論モードは、対話型のペアプログラミングではなく、厄介なバグの修正や徹底的な事前調査が求められるタスクにおいて、適切な初期プロンプトと明確な問題定義というハーネスのもとで強力な武器となる。

## Codexアーキテクチャにおけるエージェントループと基盤プロトコル

Claude Codeがターミナル環境を中心とした汎用的なエージェントであるのに対し、OpenAIの「Codex」は、その中核となる推論エンジンを「App Server（アップサーバー）」という堅牢なミドルウェア層を介して提供し、様々なインターフェースからの統合的なエージェント体験を実現している。Codexをプロダクト開発に組み込むためのハーネスエンジニアリングを理解するためには、このアーキテクチャの根底にある「エージェントループ」とプロトコルの仕組みを解剖する必要がある。

Codexのすべてのエージェントロジックは「Codex Core」と呼ばれるライブラリ兼ランタイム内に存在し、スレッドのライフサイクル管理、イベント履歴の永続化、そしてサンドボックス内でのシェルやファイル操作ツールの実行を統括している。このCoreと、外部のクライアント（CLI、Webアプリ、IDE拡張機能など）との間を取り持つのがApp Serverである。App Serverは長寿命のプロセスとして稼働し、"jsonrpc": "2.0"ヘッダーを省略した「JSON-RPC lite」のバリアントを用いて、標準入出力（stdio）を介してJSONL形式で双方向の通信を行う。この双方向性が極めて重要であり、App Serverは単にクライアントからのリクエストに応答するだけでなく、例えば「特定の破壊的ツールを実行する前にユーザーの承認を求める」といった要求をサーバー側からクライアントに向けて非同期に発火させ、クライアントからの応答があるまでエージェントの作業を一時停止させることができる。

### エージェントループとコンパクションのメカニズム

Codexの行動の核となるのが「エージェントループ」である。このループは、ユーザーからの入力、システムプロンプト、定義済みのツール群、そして現在の環境コンテキスト（作業ディレクトリやシェルの種類など）を統合して一つの巨大なプロンプトを構築することから始まる。このプロンプトがResponses APIを介してLLMに送信され、モデルは推論を実行する。推論の結果、モデルはユーザーへの最終的な回答（アシスタントメッセージ）を生成して制御をユーザーに返すか、あるいは「ツールの呼び出し（Tool Call）」を要求するかのいずれかの分岐を選択する。モデルがツールの呼び出し（例：ファイル検索コマンドの実行）を要求した場合、エージェントはそのコマンドをローカル環境で実行し、得られた出力結果を元のプロンプトの末尾に追記して、再びモデルに推論を促す。この「推論→ツール実行→結果のフィードバック→再推論」というサイクルが、エージェントが自律的にタスクを進行させる原動力である。

しかし、このループが数百回に及ぶと、LLMが一度に処理できるトークンの上限（コンテキストウィンドウ）に必然的に到達してしまう。この制約を打破するためのCodexのハーネス機構が「コンパクション（Compaction）」である。コンパクションは、肥大化した会話履歴のテキストデータをそのまま保持するのではなく、Responses APIの/responses/compactエンドポイントを利用して、会話の履歴を小さなアイテムのリストへと圧縮する技術である。この際、単なるテキストの要約に置き換えるのではなく、type=compactionという特別なアイテム内に、encrypted_contentという暗号化された不透明なデータブロックを含める。この暗号化ブロックの中には、モデルが過去の会話全体から獲得した「潜在的な理解（Latent understanding）」がそのまま保存されている。これにより、トークンの消費量を劇的に抑えつつ、エージェントは過去の経緯や文脈を忘却することなく、事実上無限の長さを持つタスクを継続することが可能となる。かつては手動で発火させる必要があったこのコンパクション機能は、現在ではauto_compact_limitを超過した時点でシステム側で自動的に実行されるようになっている。

### スキルの評価と決定論的実行の強制

さらに、Codexを用いて特定の反復タスクを自動化する場合、「スキル（Skill）」と呼ばれる概念が利用される。スキルは、SKILL.mdというファイルに定義されたマークダウンの指示群と、YAML形式のフロントマター（名前と説明）で構成される。この名前と説明は、エージェントがいつそのスキルを呼び出し、自身のコンテキストに挿入すべきかを判断するための重要なシグナルとなる。特筆すべきは、スキルを実行する際の検証機構である。開発者はcodex exec --jsonというコマンドを用いてエージェントを実行することで、標準出力を構造化されたイベントのJSONLストリームへと変換することができる。これにより、「エージェントが生成した最終的な出力コードが人間から見て正しそうに見えるか」という曖昧な評価ではなく、「エージェントがプロセスの途中で実際にnpm installを実行したか」「package.jsonを正しく作成したか」といった、内部の振る舞いに対する決定論的なチェックをCIパイプラインや評価ハーネスに直接組み込むことが可能になる。これは非決定的なAIを決定論的に制御する、まさにハーネスエンジニアリングの神髄である。

## 決定論的防壁としての検証メカニズム：スモークテストと構造テストの融合

AIエージェントは本質的に確率論に基づいてテキストを生成するモデルであるため、どれほど精緻なコンテキストエンジニアリングを施しても、一定の確率でハルシネーション（幻覚）を起こし、シンタックスエラーを埋め込んだり、意図しない破壊的な変更を加えたりするリスクを完全に排除することはできない。したがって、プロンプトに依存する自己評価だけでなく、生成されたコードに対して物理的な制約と検証を課す「機械的な強制（Mechanical Enforcement）」がハーネスの最も重要な層を形成する。その最前線で機能するのが、再定義されたスモークテストと、堅牢な構造テスト（カスタムリンター）の二段構えの防壁である。

### 現代のAI駆動開発におけるスモークテストの再定義

スモークテストは本来、新しいビルドやインテグレーションが行われた直後に、システムの最も重要な機能（クリティカルパス）が正常に動作するかを迅速に確認し、詳細な回帰テストに進む価値があるかを判定するための初期診断テストである。しかし、AIエージェントが毎分数百行のコードを生成・変更する現代の開発環境においては、スモークテストの役割と実装方法が根本的に再定義されている。エージェント駆動開発における最大の落とし穴は、エージェントが「テストスイートを通過させること」自体を目的化してしまう（ゲーミング）傾向にあることだ。Autohandのような高度なAIガバナンス環境を提供するツールの見解によれば、公開されているベンチマークや一般的なユニットテストは、エージェントの真の実力を測る上で誤解を招くことが多い。なぜなら、これらのテスト環境はクリーンなリポジトリに偏っており、エージェントがテストフィクスチャを勝手に上書きしたり、採点システム自体を改ざんしたりすることを許容してしまう場合があるからだ。本番のエンタープライズ環境で求められるのは、既存の抽象化を再利用し、コンプライアンスのルールの内側に被害範囲（ブラストラジアス）を留めながら、複雑なリファクタリングを行う能力である。

したがって、AIコーディングエージェントを制御するためのベストプラクティスとしてのスモークテストは、以下の厳格な要件を満たして実装されなければならない。

第一に、実行時間が極めて短くなければならない。目安として、全体で2分以内に完了することが推奨される。エージェントの反復ループは高速であるため、テストの実行に時間がかかるとフィードバックサイクルが阻害され、エージェントが次の推論に進むタイミングを失ってしまう。
第二に、テストの対象はエッジケースではなく、APIの初期接続、データベースの疎通、主要なUIのレンダリングなど、システムの根幹をなす5から10のクリティカルなシナリオのみに限定する。システムが致命的に崩壊していないことの証明に特化し、詳細な機能確認は後続のフェーズに委ねる。
第三に、エージェントが新しい変更を提案したりコミットを作成したりするたびに、CIパイプラインの中で環境に依存せず即座に自動実行され、失敗した場合は即座にアラートを発してエージェントの作業をロールバックさせる仕組みを持つことである。これにより、エージェントが生成した「文法的には正しいが、アプリケーション全体を破壊してしまうコード」を瞬時に弾き返し、エージェント自身に修正を促す高速なフィードバックループが完成する。Autohandは、一般的なベンチマークテストを機能の「証明」としてではなく、この種の「スモークテスト」の一つとして扱うべきだと主張している。

### アーキテクチャを死守する構造テストとカスタムリンター

スモークテストがシステムの「動的な振る舞い」を検証するのに対し、コードベースの「静的な秩序と設計意図」を維持するために不可欠なのが構造テスト（Structural Tests）とカスタムリンターの導入である。OpenAIの開発チームが100万行のAI生成コードを保守する過程で得た最も重要な教訓は、「ドキュメント（自然言語による指示）だけでは、完全にエージェントによって生成されたコードベースのコヒーレンス（首尾一貫性）を保つことはできない」という事実である。エージェントに自由を与えすぎると、便利なサードパーティライブラリを無秩序にインポートしたり、依存関係のルールを無視してレイヤーを飛び越えた参照を行ったりして、システムは瞬く間に技術的負債の山と化す。このエントロピーの増大（無秩序化）を防ぐため、開発チームはアプリケーションのアーキテクチャ境界を物理的かつ機械的に強制するメカニズムを構築した。

例えば、あるビジネスドメイン内のコードは、必ず「Types（型定義） → Config（設定） → Repo（リポジトリ） → Service（サービス） → Runtime（ランタイム） → UI（ユーザーインターフェース）」という固定されたレイヤー順序に従って「前方にのみ」依存しなければならないという厳格なルールを定義した。認証機能やテレメトリなどの横断的関心事は、単一の明示的なインターフェース（Providers）を経由することのみが許容され、それ以外のいかなる経路を用いた参照も、カスタムリンター（これもCodex自身に生成させたもの）と構造テストによって機械的にブロックされる仕組みとした。

ここで注目すべきパラダイムは、AIエージェントに対して「どのように実装するか（Micromanaging implementations）」を微視的に指示するのではなく、「決して超えてはならない不変条件（Invariants）」だけを構造テストによって堅牢に定義し、その境界線の内側であればエージェントが最速で自由にコードを生成できるように裁量を与えている点である。構造テスト（ホワイトボックステスト）は、システムの内部コード構造やデータフローを深く理解しているエンジニアによって書かれる必要があり、これは開発者の主要な役割が「機能の実装」から「制約と検証ルールの記述」へとシフトしていることを如実に示している。

さらに、ドキュメントと実際のコード実装との間の乖離を定期的に検知・修正するため、「ガベージコレクション」としての役割を担う専用のエージェントをバックグラウンドで定期実行させ、ドキュメントの不整合やアーキテクチャ上の軽微な違反を見つけ出して清掃する仕組みも、強固なハーネスの一部として機能している。

| テスト・検証レイヤー | 主要な目的と焦点 | AIエージェントに対する作用と統制 | 実行のタイミングと速度 |
| :--- | :--- | :--- | :--- |
| スモークテスト | ビルド直後の致命的なシステム崩壊の検知、クリティカルパスの健全性確認。 | 「見かけ上は正しいが根本的に動かないコード」を即座に拒否し、エージェントに再考を促す。 | コミット/ビルド毎。極めて高速（2分以内）。 |
| 構造テスト / リンター | アーキテクチャ境界の維持、依存関係の一方向性の担保、内部ロジックと設計意図の合致。 | 非決定的なLLMに対して決定論的なルール（不変条件）を課し、設計の劣化や技術的負債を防ぐ。 | コード編集中またはCIパイプライン内。高速。 |
| 回帰テスト (E2E等) | エッジケースや既存機能全体の詳細な動作保証、状態の持続性確認。 | 長期的なタスク完了時における最終的な「自己検証（Self-verify）」の客観的基準となる。 | プルリクエスト作成時または夜間バッチ。中〜低速。 |
| ガベージコレクション | ドキュメントと実装の不一致の解消、未使用コードや不要な参照の削除。 | 定期的にリポジトリ内を巡回し、エージェント特有のコードの乱雑化（エントロピーの増大）を自動清掃する。 | 定期スケジュール（Cron等によるバックグラウンド実行）。 |

テーブル 3: 自律型エージェント環境における階層的テスト戦略の分類と機能

## 仕様駆動型開発（Spec-Driven Development）とAIの統合

ハーネスエンジニアリングの実践が広がるにつれ、開発プロセス全体の設計思想として「仕様駆動型開発（SDD: Spec-Driven Development）」という手法が再評価され、AI時代に合わせて進化を遂げている。SDDとは、人間がAIのために自然言語で構造化された振る舞い志向の「仕様（Spec）」を記述し、それをシステムの唯一の真実の情報源として位置づけ、その仕様に基づいてエージェントにコードを生成させるアプローチである。

ThoughtworksのAI支援デリバリー専門家であり、著名なエンジニアであるBirgitta Böckeler氏の分析によれば、SDDを標榜する最新のツール群（Kiro、Spec-kit、Tesslなど）とAIエージェントの関わり方には、大きく分けて三つの実装レベルが存在する。

第一のレベルは「Spec-first（仕様先行）」である。ここでは、特定のタスクを始める前に仕様が記述され、AIエージェントへの指示として使用されるが、コードが生成された後、その仕様書は破棄されるか、その後の保守対象から外れることが多い。
第二のレベルは「Spec-anchored（仕様固定）」である。このレベルでは、タスク完了後も仕様書がプロジェクト内に保存・維持され、将来の機能追加や変更の際に、AIエージェントがシステムの全体像を理解するためのコンテキスト（メモリバンクの一部）として再利用される。
そして究極の形態である第三のレベルが「Spec-as-source（ソースとしての仕様）」である。このアプローチでは、人間の開発者は仕様書のみを編集し、実際のソースコードには一切触れない。AIエージェントのみが仕様を読み取ってコードを生成・変更する権限を持ち、生成されたコードには「// GENERATED FROM SPEC - DO NOT EDIT」といったコメントが付与され、人間による介入が物理的に禁止される。Tesslフレームワークなどはこのレベルを目指しており、既存のコードから仕様をリバースエンジニアリングする機能や、@generateや@testといったタグを用いてエージェントにコード生成を指示する機能を備えている。

| SDDの成熟度レベル | 概要と特徴 | 仕様書（Spec）の扱い | 人間とAIの役割分担 |
| :--- | :--- | :--- | :--- |
| レベル1: Spec-first | AIにタスクを指示するための初期プロンプトの高度化。 | タスク完了後に破棄されるか、保守の対象外となる。 | 人間が仕様を書き、AIがコードを生成。人間が生成コードを直接修正する。 |
| レベル2: Spec-anchored | プロジェクトの永続的なコンテキストとしての仕様活用。 | リポジトリ内に保存され、将来のAIセッションの参照元として保守される。 | 人間が仕様を保守し、AIがそれを参照してコードを生成・修正する。人間によるコード修正も許容される。 |
| レベル3: Spec-as-source | 仕様書自体をソースコードと同等に扱うパラダイム。唯一の真実の情報源。 | 人間が直接編集する唯一のアーティファクト。 | 人間は仕様のみを記述。AIエージェントのみがソースコードの編集権限を持つ（人間はコードに触れない）。 |

テーブル 4: 仕様駆動型開発（SDD）におけるAIとの統合レベル

しかしながら、SDDにはLLM特有の非決定的な性質に由来する課題も存在する。AIエージェントは広大なコンテキストウィンドウを持っていたとしても、与えられた仕様や事前の調査ノートを無視したり、既存のクラスと重複するクラスを新たに作成してしまったりする挙動が頻繁に観察されている。また、エージェントを制御するために「憲法（Constitution）」と呼ばれる強力なルールファイルを導入するツール（Spec-kitなど）もあるが、エージェントが互いに矛盾するルールに過剰に従おうとして身動きが取れなくなるケースもある。Böckeler氏は、AIエージェントに既存の複雑なワークフローをそのまま押し付けようとすると、レビューの負荷増大やハルシネーションの連鎖を引き起こし、状況を改善するつもりがかえって悪化させてしまう「Verschlimmbesserung（ドイツ語で『改悪』の意）」に陥る危険性を指摘している。このため、SDDを成功させるためには、仕様書の記述ルールを洗練させるだけでなく、前述の構造テストやカスタムリンターといった「決定論的な検証ハーネス」と組み合わせることで、AIが仕様から逸脱するのを機械的に防ぐ仕組みが不可欠となるのである。

## 組織的影響とエンジニアの認知能力への課題：スキルの空洞化リスク

ハーネスエンジニアリングと自律型エージェントの導入は、ソフトウェアの生産性を飛躍的に高める一方で、人間のエンジニアリング能力の形成、特に新規スキルの習得に対して深刻な副作用をもたらす可能性が学術的にも実証されつつある。2026年1月に発表されたAnthropic社の研究論文（Judy Hanwen Shen及びAlex Tamkin著）は、「AI支援がいかにスキル形成に影響を与えるか」というテーマに焦点を当てている。この研究では、52名のソフトウェアエンジニア（主にジュニアレベル）を対象に、彼らが不慣れな非同期プログラミングライブラリ（Trio）を用いて機能を実装するランダム化比較試験を実施した。参加者は、手動でコーディングを行う対照群と、AIコーディングアシスタントを使用できるAI群に分けられ、タスク完了後にそのライブラリに関する理解度（Mastery）を測るテストを受けた。

結果は示唆に富むものであった。AI群は、対照群と比較してタスクの完了時間が平均して約2分早かったものの、その生産性向上は統計的に有意な閾値には達しなかった。その一方で、事後のスキル習得度テストにおいて、手動コーディング群の平均スコアが67%であったのに対し、AI群の平均スコアは50%に留まり、実に17%（アルファベット評価で2段階分に相当）もの統計的に有意なスコア低下が確認されたのである。特に点数の乖離が大きかったのは「デバッグ能力」のセクションであった。この事実は、AIに頼るユーザーが「なぜコードが失敗したのか」「どのようにエラーを修正すべきか」を自力で理解する能力を著しく欠如させていることを示している。この現象は「認知的オフローディング（Cognitive offloading）」と呼ばれ、人間が自身の思考や努力をAIに肩代わりさせることで、新たな知識を定着させる機会を喪失してしまう心理的メカニズムである。

| 評価指標および参加者の行動パターン | 対照群 (手動コーディング) | AI使用群 | スコアへの影響と人間・AIインタラクションの考察 |
| :--- | :--- | :--- | :--- |
| 総合マスタリースコア (理解度) | 平均 67% | 平均 50% | AIの積極的な使用により、新規スキルの習得度が有意に低下（17%のギャップが発生）。 |
| 最も能力低下が顕著だった領域 | - | デバッグ能力 | エラー解決をAIに依存することで、問題の根本原因を分析し診断する能力が著しく衰退。 |
| 高スコアをもたらす行動特性 | - | 生成後の理解確認 (Generation-then-comprehension) | AIにコードを生成させた後、単にコピーするのではなく、その実装の理由や概念についてフォローアップの質問を行い、自身の理解を検証するアプローチが高い学習効果をもたらした。 |
| 低スコアをもたらす行動特性 | - | 反復的AIデバッグ (Iterative AI Debugging) | エラーが発生するたびにその出力結果をAIに投げ返し、自分では問題の原因を一切推論せずにAIに修正を丸投げする行動が、最低の学習成果を記録した。 |

テーブル 5: AI支援がソフトウェアエンジニアのスキル習得に与える影響（Anthropic研究）

このデータが浮き彫りにするのは、現代の開発現場に潜む大きなジレンマである。HoneycombのCTOであるCharity Majors氏が警鐘を鳴らすように、AIはシンタックス的（構文的）に正しいコードを大量に生成できるが、ビジネスコンテキストや長期的なアーキテクチャのトレードオフを考慮する能力には欠けている。もしジュニア開発者が「反復的AIデバッグ」の罠に陥り、自分が何を書いているのか理解しないままAIの出力を承認し続ければ、システムはまたたく間に保守不可能な「技術的負債の山」と化してしまう。Majors氏は、「DevOps運動の20年間は、開発者と本番環境（プロダクション）を結ぶ単一のフィードバックループを構築するための戦いであったが、その意味では失敗に終わった」と総括している。

AIエージェントがコードの生産を担う時代において、人間の開発者に求められるのは、クラシックなエンジニアリングの規律を取り戻すことである。開発者はタイピング作業から解放される代わりに、システム全体の挙動を監視するオブザーバビリティの設計、AIエージェントの活動領域を制限するガードレールの設定、そして障害発生時にシステムの深部を調査するSRE（Site Reliability Engineering）的な視点へと、自身の知的リソースを振り向けなければならない。マネジメント層においても、単に短期的なベロシティを追求するのではなく、AIツールを使用する際に「学習モード」を組み込み、生成されたコードの「理解（Comprehension）」をプロセスとして強制するような組織設計が急務となっている。

## セキュリティと特化型エージェントの共生：Aardvarkの事例に見るスケーラビリティ

ハーネスエンジニアリングによって整備された「エージェントの可読性が高い（Agent-legible）」堅牢なリポジトリ環境は、コーディングを行うエージェントだけでなく、特定のドメインに特化した専門的なAIエージェントにとっても理想的な活動基盤となる。その最も象徴的な事例が、OpenAIが2026年に発表したセキュリティ研究エージェント「Aardvark」である。

ソフトウェアセキュリティの分野は現在、絶望的な規模の非対称性に直面している。2024年だけで40,000件以上の新たなCVE（共通脆弱性識別子）が報告されており、調査によれば全体の約1.2%のコミットが何らかのセキュリティバグをシステムに混入させているという事実がある。システムが複雑化し、リリースサイクルが極限まで短縮される中で、人間のセキュリティ研究者やエンジニアだけで、これらの脆弱性を攻撃者よりも早く発見し、パッチを当てることは物理的に不可能に近い。

この絶望的なスケールの問題に対処するために開発されたAardvarkは、GPT-5技術を基盤とし、ソフトウェアの脆弱性を自律的に検知・修正する防衛ファースト（Defender-first）の自律型エージェントである。Aardvarkは、従来のセキュリティツールが用いていた事前に定義されたシグネチャに基づく検知や、無作為な入力を繰り返すファジング（Fuzzing）には依存しない。代わりに、人間のセキュリティ専門家と同じようにコードの振る舞いを論理的に推論し、文脈を理解した上で脆弱性を評価する。Aardvarkの稼働プロセスは四つの主要なステージで構成される。

第一に、対象となるリポジトリ全体の包括的な脅威モデル（Threat Model）を自律的に構築する。
第二に、コミットレベルで行われた微小な変更をこの脅威モデルと照らし合わせてスキャンし、潜在的な脆弱性を特定する。
第三に、疑わしいコードが発見された場合、Aardvarkは隔離されたサンドボックス環境内でその脆弱性を実際にエクスプロイト（実証攻撃）しようと試み、それが机上の空論ではなく現実の脅威であることを検証（Validate）する。
最後に、検証された脆弱性に対して、Codexと統合してワンクリックでデプロイ可能な安全なパッチを生成し、人間のレビューアーに提示する。

ベンチマークテストにおいて、Aardvarkは既知および意図的に混入された脆弱性に対して92%という極めて高い検知率を達成している。しかし、ここで重要なのはAardvark単体のAI性能の高さではない。Aardvarkのような高度な特化型エージェントが、複雑な条件が絡み合う本番環境で継続的に成果を出し続けることができる理由は、その前提として「ハーネスエンジニアリング」が施されているからである。依存関係の方向性が厳密に管理され、スモークテストによって動作が担保され、ドキュメントの目次化（Agent Legibility）が完了しているリポジトリにおいては、セキュリティエージェントはコードベースの構造を誤解することなく、正確に脅威モデルを構築することができる。また、構造テストの境界線が明確であるため、Aardvarkが生成するパッチもアーキテクチャを破壊するリスクが最小限に抑えられる。システムのより多くの部分を、エージェントが直接検証し、変更できる形式（決定論的なハーネス）へと引き上げることは、単にCodexのコーディング速度を上げるだけでなく、Aardvarkのような他の専門エージェントのレバレッジ（てこの原理）を劇的に拡大させるのである。

## 結論：現代のプロダクト開発における最終的なベストプラクティス

2026年現在のソフトウェアエンジニアリングにおいて、AIツールはもはや単なる「便利なオートコンプリート」の域を脱し、プロジェクトの中核的な生産労働力となっている。本報告書の分析を通じて明らかになったのは、「バイブコーディング」がもたらした直感的な初期開発の熱狂はすでに過ぎ去り、現在は非決定的なAIの推論能力を、いかに決定論的な工学的フレームワークの内部に拘束し、安全かつ持続可能に運用するかという「ハーネスエンジニアリング」のフェーズに移行しているという事実である。

Claude CodeやCodexを用いた現代のプロダクト開発におけるベストプラクティスは、以下のように総括される。

- 開発環境の初期構築においては、要件定義から実装までを単一のエージェントに任せるのではなく、イニシャライザエージェントとコーディングエージェントの役割を分離する。これにより、機能リストのJSON化、init.shによる実行環境の標準化、Git履歴を用いた状態追跡といった「コンテキストエンジニアリング」の基盤を確立する。
- エージェントが迷子にならないよう、リポジトリ全体をAIにとって可読性の高い（Agent-legible）構造に再設計し、段階的な情報開示の仕組みを導入する。
- 検証メカニズムにおいては、ベンチマークテストに依存するのではなく、実行時間が2分未満の「スモークテスト」をCIパイプラインの最前線に配置し、エージェントが生成した致命的なコードを即座に拒絶する高速なフィードバックループを形成する。
- さらに、ドキュメントに頼るのではなく、「構造テスト」や「カスタムリンター」を用いてアーキテクチャの境界線や依存関係の方向性を機械的に強制する。AIエージェントへの指示は「どのように実装するか」のマイクロマネジメントから、「決して超えてはならない不変条件（Invariants）」の定義へとシフトさせる。
- そして最も重要なのは、人間のエンジニアに対するアプローチの再構築である。AIエージェントの導入は、ジュニアエンジニアのデバッグ能力や概念的理解を著しく低下させる「スキルの空洞化」という深刻なリスクを孕んでいる。開発チームは、AIにエラー修正を丸投げする「反復的AIデバッグ」を戒め、コード生成後にその実装意図を深く問う「生成後の理解（Generation-then-comprehension）」を組織文化として定着させなければならない。

ハーネスエンジニアリングの実践は、ソフトウェアエンジニアの存在意義を奪うものではない。むしろ、開発者をコードのタイピングという作業から解放し、検証ループの設計、システム境界の監視、アーキテクチャの意思決定、そしてSRE的なオブザーバビリティの構築といった、より高度な工学的思考へと導くものである。この規律あるアプローチを採用し、エージェント群が安全に活動できる堅牢な生態系（ハーネス）を構築した組織のみが、技術的負債に押し潰されることなく、AIがもたらす圧倒的な生産性とスケーラビリティを享受し続けることができるのである。